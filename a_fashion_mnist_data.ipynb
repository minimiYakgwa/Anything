{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade wandb # wandb설치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0588ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchinfo # torchinfo 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd226c8",
   "metadata": {},
   "source": [
    "# 문제 1\n",
    "> ## Fashion\tMNIST\t데이터 정규화를 위한 Mean과\tStd.\t값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625af549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b16a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c961795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_PATH = str(Path(__file__).resolve().parent.parent.parent)  # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "BASE_PATH = str(Path.cwd().resolve().parent.parent) # Path.cwd() : jupyter notebook에서 Path(__file__)의 기능과 동일하게 제공함\n",
    "print(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2636e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2867f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _01_code._99_common_utils.utils import get_num_cpu_cores, is_linux, is_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa58920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "    \n",
    "    # FashionMNIST 데이터셋을 불러와 data_path에 존재하지 않다면 다운로드. 학습용이므로 suffle, transform 사용.\n",
    "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "    \n",
    "\n",
    "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
    "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
    "    print(\"Sample Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    num_data_loading_workers = get_num_cpu_cores() if is_linux() or is_windows() else 0\n",
    "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
    "    \n",
    "    img_t, _ = f_mnist_train[0]\n",
    "    print(f\"type : {type(img_t)}\")\n",
    "    print(f\"shape : {img_t.shape}\")\n",
    "    print(f\"min : {img_t.min()} max : {img_t.max()}\")\n",
    "    \n",
    "    imgs = torch.stack([img_t for img_t, _ in f_mnist_train], dim=3)\n",
    "    \n",
    "    print(f\"mean : {imgs.view(1, -1).mean(dim=-1)}\")\n",
    "\n",
    "    print(f\"std : {imgs.view(1, -1).std(dim=-1)}\")\n",
    "    \n",
    "\n",
    "    train_data_loader = DataLoader( \n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential( \n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2859, std=0.3529), # 데이터 정규화 및 torch 타입으로 변경함 ( 필수 요소 )\n",
    "    )\n",
    "\n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_test_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "    \n",
    "    # 이미지 데이터 그대로 사용하기 때문에 transform을 사용하지 않음\n",
    "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
    "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2859, std=0.3529), # torch 형태로 바꾸고, 정규화 과정을 거침 (필수요소)\n",
    "    )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _01_code._08_fcn_best_practice.c_trainer import ClassificationTrainer\n",
    "from _01_code._08_fcn_best_practice.f_mnist_train_fcn import get_mnist_data\n",
    "from _01_code._08_fcn_best_practice.e_arg_parser import get_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76335953",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = {'batch_size': 2048, }\n",
    "    wandb.init(mode=\"online\", config=config)\n",
    "    \n",
    "    # train, validation dataset을 불러옴\n",
    "    train_data_loader, validation_data_loader, f_mnist_transforms = get_fashion_mnist_data() \n",
    "    print()\n",
    "    f_mnist_test_images, test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data() # test dataset을 불러옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5606a1",
   "metadata": {},
   "source": [
    "# 문제 2\n",
    "> # Fashion\tMNIST\t데이터에\t대하여\tCNN\t학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from _01_code._99_common_utils.early_stopping import EarlyStopping\n",
    "from _01_code._99_common_utils.utils import strfdelta\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "class ClassificationTrainer:\n",
    "  def __init__(\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "  ):\n",
    "    self.project_name = project_name\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.train_data_loader = train_data_loader\n",
    "    self.validation_data_loader = validation_data_loader\n",
    "    self.transforms = transforms\n",
    "    self.run_time_str = run_time_str\n",
    "    self.wandb = wandb\n",
    "    self.device = device\n",
    "    self.checkpoint_file_path = checkpoint_file_path\n",
    "\n",
    "    # Use a built-in loss function\n",
    "    self.loss_fn = nn.CrossEntropyLoss() # 다중 분류에 사용되는 loss 함수\n",
    "    \n",
    "    self.scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1) # 100 epoch 마다 lr을 0.1정도 줄이는 schedular 정의\n",
    "\n",
    "  def do_train(self):\n",
    "    self.model.train()  # Will be explained at 'Diverse Techniques' section / 모델 학습에선 꼭 사용해야함.\n",
    "\n",
    "    loss_train = 0.0\n",
    "    num_corrects_train = 0\n",
    "    num_trained_samples = 0\n",
    "    num_trains = 0\n",
    "\n",
    "    for train_batch in self.train_data_loader:\n",
    "      input_train, target_train = train_batch\n",
    "      input_train = input_train.to(device=self.device)\n",
    "      target_train = target_train.to(device=self.device)\n",
    "\n",
    "      if self.transforms:\n",
    "        input_train = self.transforms(input_train)\n",
    "\n",
    "      output_train = self.model(input_train)\n",
    "      loss = self.loss_fn(output_train, target_train)\n",
    "      loss_train += loss.item()\n",
    "\n",
    "      predicted_train = torch.argmax(output_train, dim=-1) # 다중 분류에 사용됨.\n",
    "\n",
    "      # >>> predicted_train: tensor([5, 8, 9, 0, 9, 8, 9, 8, ..., 0, 1, 3, 7, 1, 4, 3])\n",
    "      # >>> target_train:    tensor([5, 8, 9, 2, 9, 8, 7, 8, ..., 4, 1, 9, 6, 1, 4, 3])\n",
    "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "      num_trained_samples += len(input_train)\n",
    "      num_trains += 1\n",
    "\n",
    "      self.optimizer.zero_grad() # \n",
    "      loss.backward() # \n",
    "      self.optimizer.step() # 가중치 수정\n",
    "    \n",
    "    #self.scheduler.step() # 하나의 epoch가 끝나면 호출\n",
    "\n",
    "    train_loss = loss_train / num_trains\n",
    "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "  def do_validation(self):\n",
    "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_corrects_validation = 0\n",
    "    num_validated_samples = 0\n",
    "    num_validations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in self.validation_data_loader:\n",
    "        input_validation, target_validation = validation_batch\n",
    "        input_validation = input_validation.to(device=self.device)\n",
    "        target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "        if self.transforms:\n",
    "          input_validation = self.transforms(input_validation)\n",
    "\n",
    "        output_validation = self.model(input_validation)\n",
    "        loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
    "\n",
    "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "        num_validated_samples += len(input_validation)\n",
    "        num_validations += 1\n",
    "\n",
    "    validation_loss = loss_validation / num_validations\n",
    "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "    return validation_loss, validation_accuracy\n",
    "\n",
    "  def train_loop(self):\n",
    "    early_stopping = EarlyStopping(\n",
    "      patience=self.wandb.config.early_stop_patience,\n",
    "      delta=self.wandb.config.early_stop_delta,\n",
    "      project_name=self.project_name,\n",
    "      checkpoint_file_path=self.checkpoint_file_path,\n",
    "      run_time_str=self.run_time_str\n",
    "    )\n",
    "    n_epochs = self.wandb.config.epochs\n",
    "    training_start_time = datetime.now()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      train_loss, train_accuracy = self.do_train()\n",
    "\n",
    "      if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "        validation_loss, validation_accuracy = self.do_validation()\n",
    "\n",
    "        elapsed_time = datetime.now() - training_start_time\n",
    "        epoch_per_second = 0 if elapsed_time.seconds == 0 else epoch / elapsed_time.seconds\n",
    "\n",
    "        message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "\n",
    "        print(\n",
    "          f\"[Epoch {epoch:>3}] \"\n",
    "          f\"T_loss: {train_loss:7.5f}, \"\n",
    "          f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "          f\"V_loss: {validation_loss:7.5f}, \"\n",
    "          f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "          f\"{message} | \"\n",
    "          f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "          f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "        )\n",
    "\n",
    "        self.wandb.log({\n",
    "          \"Epoch\": epoch,\n",
    "          \"Training loss\": train_loss,\n",
    "          \"Training accuracy (%)\": train_accuracy,\n",
    "          \"Validation loss\": validation_loss,\n",
    "          \"Validation accuracy (%)\": validation_accuracy,\n",
    "          \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "        })\n",
    "\n",
    "        if early_stop:\n",
    "          break\n",
    "\n",
    "    elapsed_time = datetime.now() - training_start_time\n",
    "    print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06a94b",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "# BASE_PATH: /Users/yhhan/git/link_dl\n",
    "BASE_PATH = str(Path.cwd().resolve().parent.parent)\n",
    "print(BASE_PATH)\n",
    "\n",
    "CURRENT_FILE_PATH = os.path.abspath(os.getcwd())\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "    os.makedirs(os.path.join(CURRENT_FILE_PATH, \"checkpoints\"))\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _01_code._99_common_utils.utils import get_num_cpu_cores, is_linux, is_windows\n",
    "from _01_code._08_fcn_best_practice.e_arg_parser import get_parser\n",
    "\n",
    "\n",
    "\n",
    "def get_fashion_mnist_data():\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    # FashionMNIST 데이터셋을 불러와 data_path에 존재하지 않다면 다운로드 학습용으로 Tensor화 시켜서 저장\n",
    "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.RandomRotation(10) # 기존 가져온 데이터셋에 data argumentation을 적용\n",
    "                                      ]))                               # 회전을 적용한 후 텐서화 해 저장함.\n",
    "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
    "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
    "    print(\"Sample Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    num_data_loading_workers = get_num_cpu_cores() if is_linux() or is_windows() else 0\n",
    "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
    "\n",
    "    img_t, _ = f_mnist_train[0]\n",
    "    print(f\"type : {type(img_t)}\")\n",
    "    print(f\"shape : {img_t.shape}\")\n",
    "    print(f\"min : {img_t.min()} max : {img_t.max()}\")\n",
    "\n",
    "    imgs = torch.stack([img_t for img_t, _ in f_mnist_train], dim=3)\n",
    "\n",
    "    print(f\"mean : {imgs.view(1, -1).mean(dim=-1)}\")\n",
    "\n",
    "    print(f\"std : {imgs.view(1, -1).std(dim=-1)}\")\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2859, std=0.3529), # mean, std값이 계속 -2~-2 정도의 변화가 있음\n",
    "        \n",
    "    )\n",
    "\n",
    "    return train_data_loader, validation_data_loader, f_mnist_transforms\n",
    "\n",
    "def get_fashion_mnist_test_data():\n",
    "    data_path = os.path.join(os.path.pardir, os.path.pardir, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
    "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
    "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
    "\n",
    "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
    "\n",
    "    f_mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.2859, std=0.3529),\n",
    "    )\n",
    "\n",
    "    return f_mnist_test_images, test_data_loader, f_mnist_transforms\n",
    "\n",
    "def get_cnn_model():\n",
    "    \n",
    "    class MyModel(nn.Module):\n",
    "            def __init__(self, in_channels, n_output):\n",
    "                \n",
    "                super().__init__()\n",
    "\n",
    "                self.model = nn.Sequential(\n",
    "                # B x 1 x 28 x 28 --> B x 6 x (28 - 5 + 1) x (28 - 5 + 1) = B x 6 x 24 x 24\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=(5, 5), stride=(1, 1)),\n",
    "                # B x 6 x 24 x 24 --> B x 6 x 12 x 12\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.BatchNorm2d(num_features=6, eps=1e-05, momentum=0.1), # 데이터 정규화 과정 진행\n",
    "                nn.ReLU(),\n",
    "                # B x 6 x 12 x 12 --> B x 16 x (12 - 5 + 1) x (12 - 5 + 1) = B x 16 x 8 x 8\n",
    "                nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1)),\n",
    "                # B x 16 x 8 x 8 --> B x 16 x 4 x 4\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.ReLU(),        \n",
    "                nn.Flatten(),\n",
    "                nn.Dropout(p=0.1), # 일정 확률로 뉴런을 배제함.\n",
    "                nn.Linear(256, 128),\n",
    "                nn.BatchNorm1d(num_features=128, eps=1e-05, momentum=0.1), # 데이터 정규화 과정 진행\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.1), # 일정 확률로 뉴런을 배제함.\n",
    "                nn.Linear(128, n_output),\n",
    "              )\n",
    "\n",
    "            def forward(self, x):\n",
    "              x = self.model(x)\n",
    "              return x\n",
    "\n",
    "      # 1 * 28 * 28\n",
    "    my_model = MyModel(in_channels=1, n_output=10)\n",
    "\n",
    "    return my_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'validation_intervals': args.validation_intervals, # validation을 몇번 진행할 때마다 early_stop을 검사하는지에 대한 값\n",
    "        'learning_rate': 1e-3, #args.learning_rate, # 학습률\n",
    "        'early_stop_patience': 20, #args.early_stop_patience, # early_stop이 발생하려고 할 때 몇 번 참을 건지에 대한 값.\n",
    "        'early_stop_delta': 0.001 #args.early_stop_delta # 이전 값보다 어느정도 차이가 벌어졌을 때 early_stop을 진행할 건지.\n",
    "      }\n",
    "\n",
    "    project_name = \"cnn_f_mnist\"\n",
    "    wandb.init(\n",
    "        mode=\"online\",# if args.wandb else \"disabled\",\n",
    "        project=project_name,\n",
    "        notes=\"f_mnist Homework with cnn\",\n",
    "        tags=[\"cnn\", \"f_mnist\"],\n",
    "        name=run_time_str,\n",
    "        config=config\n",
    "      )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on device {device}.\")\n",
    "\n",
    "    train_data_loader, validation_data_loader, f_mnist_transforms = get_fashion_mnist_data()\n",
    "    print()\n",
    "    f_mnist_test_images, test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data()\n",
    "\n",
    "    model = get_cnn_model()\n",
    "    model.to(device)\n",
    "    wandb.watch(model)\n",
    "\n",
    "\n",
    "    info = summary(model=model, input_size=(1, 1, 28, 28)) # 모델에 대항 정보를 출력함. input_size는 정확하게 입력해야 오류가 없음\n",
    "    print(info) # jupyter notebook은 summary만 설정해선 출력되지 않아 임의로 출력시킴.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate, weight_decay=0.0005) # Adam optimizer 사용.\n",
    "\n",
    "    classification_trainer = ClassificationTrainer(\n",
    "        project_name, model, optimizer, train_data_loader, validation_data_loader, f_mnist_transforms,\n",
    "        run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n",
    "      )\n",
    "    classification_trainer.train_loop()\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = get_parser()\n",
    "    args = parser.parse_args([])\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cfde9",
   "metadata": {},
   "source": [
    "# 모델 학습에 대한 고찰\n",
    "\n",
    "- 기본 조건으로 학습 시\n",
    "> validation accuracy 88%\n",
    "- adam, batch normalization, drop, data augmentation, regularzation을 무작위 값으로 적용한 후\n",
    "> validation accuracy 89.46% | test accuracy 89.070% <br>\n",
    "> EARLY STOPPED : 570\n",
    "- ReLU -> LeakyReLu, lr decay 추가로 사용한 후\n",
    "> validation accuracy 89.02% | test accuracy 89.210%\n",
    "> LeakyReLu를 사용할 때가 오히려 ReLU보다 나빠지고 있다는 것을 알 수 있음\n",
    "> fashion mnist 데이터에게만 ReLU가 더 유리한건지, 아니면 이미지 데이터 전체에게 ReLU가 더 유리한건지 생각할 수 있음.\n",
    "- data augmentation 1개 추가 적용 \n",
    "> validation acuuracy 88.09% | test accuracy 89.0%\n",
    "> data augmentation을 여러개 적용하니 오히려 떨어지는 것을 알 수 있었음.\n",
    "> 데이터가 더 복잡해졌기 때문에 과소적합이 아닌가 싶기도 하고 lr을 늘리면 더 좋아지지 않을까 생각됨.\n",
    "- drop: 0.5 -> 0.4, learning rate 1e-3 -> 1e-4, batch norm-momentum 0.1 -> 0.5\n",
    "> validation acuuracy 87.7% | test accuracy 87.23%\n",
    "> 이전보다 많이 낮아졌기 때문에 lr을 낮추고 batch normalization의 momentum을 높이는 것은 지양.\n",
    "- batch norm_momentum 0.5 -> 0.1, eps 1e-5 -> 1e-3\n",
    "> validation acuuracy 87.46% | test accuracy 87.440%\n",
    "> batch normalization값을 변경하는 것은 성능을 끌어올리는데 큰 영향을 주지 않는 것으로 생각됨.\n",
    "- batch norm_mometum 0.1 -> 0.9\n",
    "> validation acuuracy 86.14% | test accuracy 87.350%\n",
    "> 역시 normalization momentum값은 기존 값으로 유지\n",
    "- dropout => 0.1, weight_decay => 0.0005\n",
    "> 정확도가 어느정도 올라감.\n",
    "> dropout값과 weight_decay값은 낮추는게 모델 성능에 도움이 되는 것으로 생각함.\n",
    "- LeakyReLU -> ReLU\n",
    "> 예상대로 성능이 올라감\n",
    "- batch size : 2048 -> 1024\n",
    "> 모델 성능이 기존 91.7%에서 90.7%로 떨어짐\n",
    "- batch size : 2048 -> 3072\n",
    "> 역시 모델 성능이 기존보다 떨어짐\n",
    "> batch size는 기존 2048이 맞는듯\n",
    "- schedular 추가 ( 10 epoch 마다 실행)\n",
    "> 학습이 기존보다 떨어짐\n",
    "- schedluar : 10 epoch -> 100 epoch\n",
    "> 학습이 기존보다 떨어짐\n",
    "> schedular를 사용하지 않던지, stepLR말고 다른 schedular를 사용해야 할것으로 생각됨.\n",
    "- transform에서 nn.Sequential 대신 transforms.Compose를 사용할 수도 있다는 것을 알 수 있었음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146929c1",
   "metadata": {},
   "source": [
    "# 문제 3, 4\n",
    "> # 학습 완료된 모델로 테스트 데이터 Accuracy\t확인하기\n",
    "> # 샘플 테스트 데이터 분류 예측 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b1722e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# BASE_PATH: /Users/yhhan/git/link_dl\n",
    "BASE_PATH = str(Path.cwd().resolve().parent.parent)\n",
    "print(BASE_PATH)\n",
    "\n",
    "CURRENT_FILE_PATH = os.path.abspath(os.getcwd())\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "    os.makedirs(os.path.join(CURRENT_FILE_PATH, \"checkpoints\"))\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "\n",
    "\n",
    "from _01_code._08_fcn_best_practice.d_tester import ClassificationTester # 기존 코드 ClassificationTester를 그대로 사용함\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    f_mnist_test_images, test_data_loader, f_mnist_transforms = get_fashion_mnist_test_data()\n",
    "    test_model = get_cnn_model()\n",
    "    classification_tester = ClassificationTester(\n",
    "        \"cnn_f_mnist\", test_model, test_data_loader, f_mnist_transforms, CHECKPOINT_FILE_PATH\n",
    "      )\n",
    "    classification_tester.test()\n",
    "\n",
    "    print()\n",
    "    \n",
    "    for i in range(9):\n",
    "        img, label = f_mnist_test_images[i]\n",
    "        print(\"     LABEL:\", label)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        output = classification_tester.test_single(\n",
    "        torch.tensor(np.array(f_mnist_test_images[i][0])).unsqueeze(dim=0).unsqueeze(dim=0))\n",
    "        print(\"PREDICTION:\", output)\n",
    "    \n",
    "    j = 12\n",
    "    img, label = f_mnist_test_images[j]\n",
    "    print(\"     LABEL:\", label)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    torch.tensor(np.array(f_mnist_test_images[j][0])).unsqueeze(dim=0).unsqueeze(dim=0).shape: (1, 1, 28, 28)\n",
    "    output = classification_tester.test_single(\n",
    "        torch.tensor(np.array(f_mnist_test_images[j][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "      )\n",
    "    print(\"PREDICTION:\", output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e667efc",
   "metadata": {},
   "source": [
    "# 테스트 결과\n",
    "- 9개의 테스트 샘플의 경우 정답을 맞췄지만, 마지막 한 테스트 샘플의 경우 정답을 맞추기 못하였다.\n",
    "- 7번 sneakers와 5번 sandle은 모두 신발의 형태를 띄고 있어 대략적으로 보면 유사하다고 생각할 수 있을 것 같다.\n",
    "- 아마 pooling이 부족해서 모델이 세부적인 특징을 학습한 것이 아니라 전체적인 특징을 학습한 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343611d",
   "metadata": {},
   "source": [
    "# 숙제 후기\n",
    "> 강의 시간에 하셨던 \"경험이 중요하다\"라는 내용이 확 와닫는 계기가 되었습니다. 처음엔 단지 모든 방법을 다 추가해서 돌려봤더니 오히려 아무것도 없을 때의 정확도보다 오히려 더 떨어지는 결과가 나왔으며, 그 이후로 값을 늘리거나 줄이면서 어떻게 하면 정확도가 올라가는지 계속 모델을 학습시켜봤습니다. 또한 하나의 요소만 고려하는 것이 아닌, 가령 \"dropout 값만 올리면 정확도가 좋아질 수 있다\" 이런 것이 아니라 \"데이터 종류에 따라 정확도가 높아지는 Layer개수가 다르고 Layer 개수에 따라 좋은 dropout값이 다르다\" 처럼 여러 요소들이 서로 엮여있어정확도를 올리기 위한 값을 조정하기 까다로웠습니다. 과제 제출 2주 전부터 모델 학습을 밤새 돌렸는데 학습 시간이 적어도 2시간 많으면 6시간이 걸리다 보니 아직 여러 방법을 시도하지 못해 너무 아쉽다는 생각이 들었고, 모델 정확도를 94%이상으로 올리지 못한 것 역시 너무 아깝다는 생각이 들었습니다. 주피터 노트북에서 모델을 돌려보면서 data argumentation 부분에서 계속 커널이 나가는 경우가 많아 모델 학습이 제한이 걸렸는데, 콘솔로 바꿔서 진행하지 못한 것이 아쉬웠습니다.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0fcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "PyTorch 2.3 (NGC 24.03/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
